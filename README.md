# Content Scraper

The content scraper is a Node.js command line app that scrapes data from an ecommerce site to get the latest prices and saves them to a spreadsheet in CSV format which can then be used by other applications to populate a database. The application runs once a day.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

You will need to have Node.js and NPM installed. The best way is to install with homebrew - for instructions on how to install check out [this teamtreehouse blog post](http://blog.teamtreehouse.com/install-node-js-npm-mac). Once you have done that running NPM install will install the following npm packages:

[Osmosis](https://github.com/rchipka/node-osmosis)
[json2csv](https://www.npmjs.com/package/json2csv)

```
npm install
```

### How to run Content-Scraper

A step by step series of examples that tell you have to get a development env running

To start the program, simply run:

```
npm start
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo


## Authors

* **Kate Ross** - *Initial work* - [Kaeross](https://github.com/kaeross)